





get_ipython().getoutput("pip install kaggle")


import os
dir_path = "./data"
os.makedirs(dir_path, exist_ok=True)
get_ipython().getoutput("kaggle datasets download -d mczielinski/bitcoin-historical-data -p data/ --unzip")
get_ipython().getoutput("rm -rvf data/data/")





EPOCHS = 30
BATCH_SIZE = 64
VAL_SIZE = 1000
LOOKBACK_STEPS = 10
SHIFTING_LOOKBACK_STEPS = 1
SHIFTING_TARGET_STEPS= 10
TIME_INTERVAL = 30





from sklearn.metrics import mean_squared_error,mean_absolute_error
import matplotlib.pyplot as plt
import mlflow
import mlflow.tensorflow
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
import math
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential # type: ignore
from tensorflow.keras.layers import Dense,LSTM,Dropout # type: ignore
import tensorflow as tf
from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError
from tensorflow.keras.callbacks import ModelCheckpoint # type: ignore
import json
import keras_tuner
import keras_tuner as kt
from keras_tuner import Hyperband
from keras_tuner import RandomSearch
plt.style.use('fivethirtyeight')
import os





df = pd.read_csv('data/btcusd_1-min_data.csv')
df 





df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')
df.set_index('Timestamp', inplace=True)
df1 = df.interpolate()
df1 = df1.iloc[::TIME_INTERVAL]
df = df1
df





plt.figure(figsize=(16,8))
plt.title('Price History')
plt.plot(df['Close'])
plt.xlabel('DATE')
plt.ylabel('PRICE USD')
plt.show()





# Define features and target
target_col = 'Close'
features = ['Close' ]

def create_sequences(data, target_col, lookback_steps, shifting_lookback_steps, shifting_target_steps=0):
    X, y = [], []
    for i in range(0, math.ceil((len(data) - lookback_steps)/shifting_lookback_steps)-shifting_target_steps):
        X.append(data.iloc[i*shifting_lookback_steps:(shifting_lookback_steps*i) + lookback_steps][features].values)
        y.append(data.iloc[(i*shifting_lookback_steps)+lookback_steps+shifting_target_steps][target_col])
    return np.array(X), np.array(y)


# Create sequences first
X, y = create_sequences(df, target_col, lookback_steps=LOOKBACK_STEPS, shifting_lookback_steps=SHIFTING_LOOKBACK_STEPS, shifting_target_steps=SHIFTING_TARGET_STEPS)  # Adjust time steps as needed

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = X[:-VAL_SIZE], X[-VAL_SIZE:], y[:-VAL_SIZE], y[-VAL_SIZE:]

# Initialize scalers for X (features) and y (target)
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()

# Fit and transform the training data
X_train_scaled = scaler_X.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)
y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))

# Transform the validation data
X_val_scaled = scaler_X.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)
y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1))









class CustomLSTMCell(tf.keras.layers.Layer):
    def __init__(self, units, activation='tanh', recurrent_activation='sigmoid', use_bias=True, recurrent_dropout=0.0, **kwargs):
        super(CustomLSTMCell, self).__init__(**kwargs)
        self.units = units
        self.activation = tf.keras.activations.get(activation)
        self.recurrent_activation = tf.keras.activations.get(recurrent_activation)
        self.use_bias = use_bias
        self.recurrent_dropout = recurrent_dropout

    def build(self, input_shape):
        self.input_dim = input_shape[-1] # features number
        
        self.W_f = self.add_weight(shape=(self.input_dim + self.units, self.units), initializer='random_normal', name='W_f')
        self.b_f = self.add_weight(shape=(self.units,), initializer='zeros', name='b_f') if self.use_bias else None
        
        self.W_i = self.add_weight(shape=(self.input_dim + self.units, self.units), initializer='random_normal', name='W_i')
        self.b_i = self.add_weight(shape=(self.units,), initializer='zeros', name='b_i') if self.use_bias else None
        
        self.W_c = self.add_weight(shape=(self.input_dim + self.units, self.units), initializer='random_normal', name='W_c')
        self.b_c = self.add_weight(shape=(self.units,), initializer='zeros', name='b_c') if self.use_bias else None
        
        self.W_o = self.add_weight(shape=(self.input_dim + self.units, self.units), initializer='random_normal', name='W_o')
        self.b_o = self.add_weight(shape=(self.units,), initializer='zeros', name='b_o') if self.use_bias else None

        self.W_s = self.add_weight(shape=(self.input_dim + self.units, self.units), initializer='random_normal', name='W_s')
        self.b_s = self.add_weight(shape=(self.units,), initializer='zeros', name='b_s') if self.use_bias else None

        self.W_ff = self.add_weight(shape=(self.units, self.units), initializer='random_normal', name='W_ff')
        self.b_ff = self.add_weight(shape=(self.units,), initializer='zeros', name='b_ff') if self.use_bias else None
        
        self.W_fe = self.add_weight(shape=(self.units, self.units), initializer='random_normal', name='W_fe')
        self.b_fe = self.add_weight(shape=(self.units,), initializer='zeros', name='b_fe') if self.use_bias else None
        
        self.W_z = self.add_weight(shape=(self.units, self.units), initializer='random_normal', name='W_z')
        self.b_z = self.add_weight(shape=(self.units,), initializer='zeros', name='b_z') if self.use_bias else None
        
        self.W_B = self.add_weight(shape=(self.input_dim + self.units, self.units), initializer='random_normal', name='W_B')
        self.b_B = self.add_weight(shape=(self.units,), initializer='zeros', name='b_B') if self.use_bias else None
        
        

    def call(self, inputs, states, training=None):
        h_t, c_t, fe_t = states
        if 0 < self.recurrent_dropout < 1 and training:
            h_t = tf.nn.dropout(h_t, rate=self.recurrent_dropout)

        concat_h_t = tf.concat([inputs, h_t], axis=-1)
        concat_fe_t = tf.concat([inputs, fe_t], axis=-1)
        concat_c_t = tf.concat([inputs, c_t], axis=-1)
        fe_hat = tf.matmul(concat_fe_t,self.W_s) + (self.b_s if self.use_bias else 0)
        fe_h= fe_hat + tf.matmul(concat_h_t,(1-self.W_s))+ (self.b_s if self.use_bias else 0)
        

        B_hat= tf.matmul(concat_c_t, self.W_B) + (self.b_B if self.use_bias else 0)
        f_t = self.recurrent_activation(tf.matmul(concat_h_t, self.W_f) + (self.b_f if self.use_bias else 0))
        i_t = self.recurrent_activation(tf.matmul(concat_h_t, self.W_i) + (self.b_i if self.use_bias else 0))
        c_hat_t = self.activation(tf.matmul(concat_h_t, self.W_c) + (self.b_c if self.use_bias else 0))
        o_t = self.recurrent_activation(tf.matmul(concat_h_t, self.W_o) + (self.b_o if self.use_bias else 0))
  
        fe_1 = self.recurrent_activation(tf.matmul(B_hat,self.W_z) + (self.b_z if self.use_bias else 0))
        fe_2 = self.activation(tf.matmul(B_hat,self.W_fe) + (self.b_fe if self.use_bias else 0))


        fe_f = tf.matmul(f_t, self.W_ff) + (self.b_ff if self.use_bias else 0)

        c_t_next = f_t * c_t + i_t * c_hat_t
        h_t_next = o_t * self.activation(c_t_next)
        fe_1_2=fe_1 * fe_2
        fe_ff = fe_t * fe_f
        fe_t_next=fe_1_2+fe_ff
        
        return h_t_next, [h_t_next, c_t_next, fe_t_next]
    

    def get_config(self):
        config = super(CustomLSTMCell, self).get_config()
        config.update({
            'units': self.units,
            'activation': tf.keras.activations.serialize(self.activation),
            'recurrent_activation': tf.keras.activations.serialize(self.recurrent_activation),
            'use_bias': self.use_bias,
            'recurrent_dropout': self.recurrent_dropout,
        })
        return config


class CustomLSTM(tf.keras.layers.Layer):
    def __init__(self, units, activation='tanh', recurrent_activation='sigmoid', use_bias=True, return_sequences=False, return_state=False, recurrent_dropout=0.0, unroll=False, **kwargs):
        super(CustomLSTM, self).__init__(**kwargs)
        self.units = units
        self.return_sequences = return_sequences
        self.return_state = return_state
        self.unroll = unroll
        self.cell = CustomLSTMCell(units, activation=activation, recurrent_activation=recurrent_activation, use_bias=use_bias, recurrent_dropout=recurrent_dropout)
        
    def call(self, inputs, training=None):
        batch_size = tf.shape(inputs)[0]
        seq_length = tf.shape(inputs)[1]
        
        h_t = tf.zeros((batch_size, self.units))
        c_t = tf.zeros((batch_size, self.units))
        fe_t = tf.zeros((batch_size, self.units))
        
        states = [h_t, c_t, fe_t]
        
        inputs_transposed = tf.transpose(inputs, [1, 0, 2])
        
        def step(prev_states, x_t):
            
            h_t, c_t, fe_t = prev_states
            
            h_t, [h_t, c_t, fe_t] = self.cell(x_t, [h_t, c_t, fe_t], training=training)
            
            return [h_t, c_t, fe_t]

        if self.unroll:
            # Unroll the loop manually if unroll=True
            outputs = []
            for i in range(seq_length):
                states = step(states, inputs_transposed[i])
                outputs.append(states[0])
            outputs = tf.stack(outputs, axis=0)
            
        else:
            states = tf.scan(step, inputs_transposed, initializer=states, parallel_iterations=1)
            outputs = states[0]
            
        
        outputs = tf.transpose(outputs, [1, 0, 2])
        
        final_states = [states[0][-1], states[1][-1]]
        
        if self.return_sequences:
            if self.return_state:
                return outputs, final_states
            return outputs
        
        if self.return_state:
            return outputs[:, -1, :], final_states
        return outputs[:, -1, :]
    
    def get_config(self):
        config = super(CustomLSTM, self).get_config()
        config.update({
            'units': self.units,
            'activation': tf.keras.activations.serialize(self.cell.activation),
            'recurrent_activation': tf.keras.activations.serialize(self.cell.recurrent_activation),
            'use_bias': self.cell.use_bias,
            'return_sequences': self.return_sequences,
            'return_state': self.return_state,
            'recurrent_dropout': self.cell.recurrent_dropout,
            'unroll': self.unroll,
        })
        return config









inputs = tf.keras.Input(shape=(X_train_scaled.shape[1],X_train_scaled.shape[2]))
x = CustomLSTM(16, return_sequences=True)(inputs)
#x = Dropout(0.2)(x)
#x = Dense(16)(x)
x = CustomLSTM(24, return_sequences=True)(x)
#x = Dropout(0.2)(x)
x = CustomLSTM(24)(x)
#x = Dropout(0.2)(x)
x = Dense(1)(x)

model_Relstm = tf.keras.Model(inputs, x)
model_Relstm.summary()
model_Relstm.compile(optimizer='adam', loss='mse', metrics=['mae','mape','mse','msle','cosine_similarity'])

history_Relstm=model_Relstm.fit(X_train_scaled,
                                  y_train_scaled,batch_size=BATCH_SIZE,
                                  epochs=EPOCHS,
                                  validation_data=(X_val_scaled,y_val_scaled))





inputs = tf.keras.Input(shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]))
x = tf.keras.layers.LSTM(32, return_sequences=True)(inputs)
#x = tf.keras.layers.Dropout(0.2)(x)
#x = Dense(16)(x)
x = tf.keras.layers.LSTM(32, return_sequences=True)(x)
#x = tf.keras.layers.Dropout(0.2)(x)
x = tf.keras.layers.LSTM(32)(x)
#x = tf.keras.layers.Dropout(0.2)(x)
x = tf.keras.layers.Dense(1)(x)

model_lstm = tf.keras.Model(inputs, x)
model_lstm.compile(optimizer='adam', loss='mse', metrics=['mae', 'mape', 'mse', 'msle', 'cosine_similarity'])
model_lstm.summary()

history_lstm = model_lstm.fit(
        X_train_scaled, y_train_scaled, 
        batch_size=BATCH_SIZE, 
        epochs=EPOCHS, 
        validation_data=(X_val_scaled, y_val_scaled))








# Ensure the input shape for X_val_scaled is (num_samples, time_steps, num_features)
# If X_val_scaled has the correct shape, you can proceed with prediction
Relstm_y_pred_val_scaled = model_Relstm.predict(X_val_scaled)
lstm_y_pred_val_scaled = model_lstm.predict(X_val_scaled)  

# Inverse transform the predicted and actual values
Relstm_y_pred_val_original = scaler_y.inverse_transform(Relstm_y_pred_val_scaled).flatten()
lstm_y_pred_val_original = scaler_y.inverse_transform(lstm_y_pred_val_scaled).flatten()

y_val_original = y_val  # If you haven't scaled y_val, keep it as is

# Calculate evaluation metrics
print("Evaluation for FLSTM::::::::::::::::::::::::::::::::")
mse = mean_squared_error(y_val_original, Relstm_y_pred_val_original)
mae = mean_absolute_error(y_val_original, Relstm_y_pred_val_original)
rmse = tf.sqrt(mse).numpy()
# Print the evaluation results
print(f"Mean Squared Error (MSE) on Validation Set for ReLSTM is : {mse}")
print(f"Mean Absolute Error (MAE) on Validation Set for ReLSTM : {mae}")
print(f"Root Mean Squared Error (RMSE) on Validation Set for ReLSTM : {rmse}")
print("Evaluation for LSTM::::::::::::::::::::::::::::::::")
mse = mean_squared_error(y_val_original, lstm_y_pred_val_original)
mae = mean_absolute_error(y_val_original, lstm_y_pred_val_original)
rmse = tf.sqrt(mse).numpy()
# Print the evaluation results
print(f"Mean Squared Error (MSE) on Validation Set for LSTM is : {mse}")
print(f"Mean Absolute Error (MAE) on Validation Set for LSTM is : {mae}")
print(f"Root Mean Squared Error (RMSE) on Validation Set for LSTM is : {rmse}")





# Plotting the actual vs predicted values
plt.figure(figsize=(14, 7))
plt.plot(y_val_original, label='Actual Values', color='green', alpha=0.6)
plt.plot(Relstm_y_pred_val_original, label='Predicted ReLSTM', color='red', alpha=0.6)
plt.plot(lstm_y_pred_val_original, label='Predicted lstm', color='blue', alpha=0.6)

plt.title('Actual vs Predicted Values on Validation Set')
plt.xlabel('Samples')
plt.ylabel('Target Variable')
plt.legend()
plt.grid()

plt.savefig("predictions_plot.png", dpi=300, bbox_inches='tight')

plt.show()
